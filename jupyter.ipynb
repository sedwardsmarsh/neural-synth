{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer, LSTM, GRU, Dense, Flatten, Conv1D\n",
    "import glob\n",
    "import os\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import midiDriver\n",
    "import audioRecorder\n",
    "\n",
    "\n",
    "def esr(signal_a, signal_b) -> float:\n",
    "    '''Returns the Error-to-Signal Ratio.\n",
    "\n",
    "    Keyword arguments:\n",
    "    signal_a -- the groundtruth signal\n",
    "    signal_b -- the predicted signal\n",
    "    '''\n",
    "    power = 2.0\n",
    "    numerator = np.sum(np.power(np.subtract(signal_a, signal_b), power))\n",
    "    denominator = np.sum(np.power(signal_a, power))\n",
    "    return np.divide(numerator, denominator)\n",
    "    \n",
    "\n",
    "def normalize(array: Union[List,ndarray], scale_max: int=1, scale_min: int=0) -> List:\n",
    "    '''Returns a normalized array.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    array -- array to normalize\n",
    "    scale_max -- maximum value to scale between\n",
    "    scale_min -- minimum value to scale between\n",
    "\n",
    "    Source: https://www.geeksforgeeks.org/how-to-normalize-an-array-in-numpy-in-python/\n",
    "    '''\n",
    "    scaler = MinMaxScaler(feature_range=(scale_min, scale_max))\n",
    "    return scaler.fit_transform(array)\n",
    "\n",
    "\n",
    "def partition_dataset(data_path: str='data/simple_dataset/01/*', train_perc: float=0.8) -> Tuple[List, List, List, List]: \n",
    "    '''Partition into train, train_labels & test, test_labels datasets.\n",
    "\n",
    "    Keyword arguments:\n",
    "    data_path -- where the data lives\n",
    "    '''\n",
    "    assert train_perc < 1, 'train_perc must be less than 1'\n",
    "    data_paths = glob.glob(data_path)\n",
    "    split_idx = int(0.8 * len(data_paths))\n",
    "    train_paths, test_paths = data_paths[:split_idx], data_paths[split_idx:]\n",
    "    train_data, test_data = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "    for file in train_paths:\n",
    "        _, data = read(file)\n",
    "        train_data.append(data)\n",
    "        train_labels.append(os.path.basename(file).split('.')[0])\n",
    "    for file in test_paths:\n",
    "        _, data = read(file)\n",
    "        test_data.append(data)\n",
    "        test_labels.append(os.path.basename(file).split('.')[0])\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "\n",
    "def make_model(input_shape: Tuple[int, int], num_output_nodes: int=3) -> Sequential:\n",
    "    '''Return a model.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    num_output_nodes -- number of nodes on the output layer\n",
    "    '''\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=input_shape),\n",
    "        # units = 8 is a value taken from https://arxiv.org/pdf/2009.02833.pdf\n",
    "        GRU(units=8, return_sequences=True), \n",
    "        Dense(num_output_nodes)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition dataset\n",
    "train_data_raw, train_labels_raw, test_data_raw, test_labels_raw = partition_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00% train data normalization complete\n",
      "0.10% train data normalization complete\n",
      "0.20% train data normalization complete\n",
      "0.30% train data normalization complete\n",
      "0.40% train data normalization complete\n",
      "0.50% train data normalization complete\n",
      "0.60% train data normalization complete\n",
      "0.70% train data normalization complete\n",
      "0.80% train data normalization complete\n",
      "0.90% train data normalization complete\n",
      "0.00% test data normalization complete\n",
      "0.10% test data normalization complete\n",
      "0.20% test data normalization complete\n",
      "0.30% test data normalization complete\n",
      "0.40% test data normalization complete\n",
      "0.50% test data normalization complete\n",
      "0.60% test data normalization complete\n",
      "0.70% test data normalization complete\n",
      "0.80% test data normalization complete\n",
      "0.90% test data normalization complete\n"
     ]
    }
   ],
   "source": [
    "# normalize datasets\n",
    "train_data = []\n",
    "for i, d in enumerate(train_data_raw):\n",
    "    if i % (len(train_data_raw) * 0.1) == 0:\n",
    "        print(f'{i/len(train_data_raw):.2f}% train data normalization complete')\n",
    "    train_data.append(normalize(d))\n",
    "test_data = []\n",
    "for i, d in enumerate(test_data_raw):\n",
    "    if i % (len(test_data_raw) * 0.1) == 0:\n",
    "        print(f'{i/len(test_data_raw):.2f}% test data normalization complete')\n",
    "    test_data.append(normalize(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse labels\n",
    "train_labels = []\n",
    "for l in train_labels_raw:\n",
    "    train_labels.append([param_pair[1] for param_pair in eval(l)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape features & labels \n",
    "train_data = np.asarray(train_data)\n",
    "test_data = np.asarray(test_data)\n",
    "train_data = np.reshape(train_data, (train_data.shape[0], 1, train_data.shape[1]))\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], 1, test_data.shape[1]))\n",
    "\n",
    "train_labels = np.asarray(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "type(y_true)=<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "y_true=<tf.Tensor 'IteratorGetNext:1' shape=(32, 3) dtype=int64>\n",
      "type(y_pred)=<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "y_pred=<tf.Tensor 'sequential_9/dense_9/BiasAdd:0' shape=(32, 1, 3) dtype=float32>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/lf/mzhb79q13fsfdfpwq_qqcrvr0000gn/T/ipykernel_54505/3501082877.py\", line 26, in esr_tf  *\n        print(f'{y_true.eval()=}')\n\n    ValueError: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/sadedwar/code/fun/ga-synth/jupyter.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sadedwar/code/fun/ga-synth/jupyter.ipynb#ch0000005?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m make_model(input_shape\u001b[39m=\u001b[39mtrain_data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sadedwar/code/fun/ga-synth/jupyter.ipynb#ch0000005?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sadedwar/code/fun/ga-synth/jupyter.ipynb#ch0000005?line=4'>5</a>\u001b[0m               loss\u001b[39m=\u001b[39mesr_tf,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sadedwar/code/fun/ga-synth/jupyter.ipynb#ch0000005?line=5'>6</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sadedwar/code/fun/ga-synth/jupyter.ipynb#ch0000005?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_data, train_labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1189\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1181'>1182</a>\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1182'>1183</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1183'>1184</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1184'>1185</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1185'>1186</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1186'>1187</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1187'>1188</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1188'>1189</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1189'>1190</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py?line=1190'>1191</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=152'>153</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=153'>154</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=154'>155</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/sadedwar/miniforge3/envs/env_tf_and_audio/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/lf/mzhb79q13fsfdfpwq_qqcrvr0000gn/T/ipykernel_54505/3501082877.py\", line 26, in esr_tf  *\n        print(f'{y_true.eval()=}')\n\n    ValueError: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`\n"
     ]
    }
   ],
   "source": [
    "# make, compile and fit the ML model\n",
    "# input_shape must omit batch size, i.e. : [time steps, features]\n",
    "model = make_model(input_shape=train_data.shape[1:])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=esr_tf,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "535c32cf7da711053f7d18c8747577fa07283e6873ea146110942432080a695a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('env_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
